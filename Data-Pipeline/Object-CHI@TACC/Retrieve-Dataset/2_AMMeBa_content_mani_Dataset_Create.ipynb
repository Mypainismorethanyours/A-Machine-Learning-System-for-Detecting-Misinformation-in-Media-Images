{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# ‚úÖ Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- Config ----------\n",
        "drive_input_dir = \"/content/drive/MyDrive/AMMeBa_Dataset\"\n",
        "main_zip_path = os.path.join(drive_input_dir, \"all_images_batches.zip\")\n",
        "label_files = [\n",
        "    os.path.join(drive_input_dir, \"labels_new_3.csv\"),\n",
        "    os.path.join(drive_input_dir, \"labels_new_3 (1).csv\"),\n",
        "    os.path.join(drive_input_dir, \"labels_new_3 (2).csv\"),\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6fjWwioLXww",
        "outputId": "d8e1a735-ac3f-48df-d657-13aaef47904e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5wZwjIoIgUV"
      },
      "outputs": [],
      "source": [
        "# ---------- Step 1: Unzip all_images_batches.zip ----------\n",
        "unpack_dir = \"/content/all_images_batches\"\n",
        "os.makedirs(unpack_dir, exist_ok=True)\n",
        "\n",
        "print(\"üì¶ Unzipping all_images_batches.zip...\")\n",
        "with zipfile.ZipFile(main_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unpack_dir)\n",
        "\n",
        "# ---------- Step 2: Unzip all image batch zips ----------\n",
        "image_dir = \"/content/images_all\"\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "batch_zips = [f for f in os.listdir(unpack_dir) if f.endswith(\".zip\")]\n",
        "print(f\"üì¶ Found {len(batch_zips)} image batch files.\")\n",
        "for bz in tqdm(batch_zips, desc=\"Extracting image batches\"):\n",
        "    with zipfile.ZipFile(os.path.join(unpack_dir, bz), 'r') as z:\n",
        "        z.extractall(image_dir)\n",
        "\n",
        "# ---------- Step 3: Load and merge all CSVs ----------\n",
        "df_list = [pd.read_csv(f) for f in label_files]\n",
        "labels_df = pd.concat(df_list).reset_index(drop=True)\n",
        "\n",
        "# ---------- Step 4: Clean and filter ----------\n",
        "labels_df[\"disqualified\"] = labels_df[\"disqualified\"].astype(str).str.strip().str.upper()\n",
        "num_disqualified = (labels_df[\"disqualified\"] == \"TRUE\").sum()\n",
        "labels_df = labels_df[labels_df[\"disqualified\"] != \"TRUE\"].reset_index(drop=True)\n",
        "\n",
        "print(f\"üßπ Disqualified entries removed: {num_disqualified}\")\n",
        "print(f\"üü¢ Remaining entries: {len(labels_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- Step 5: Sort by submission_time ----------\n",
        "labels_df[\"submission_time\"] = pd.to_datetime(labels_df[\"submission_time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "labels_df = labels_df.sort_values(by=\"submission_time\").reset_index(drop=True)\n",
        "\n",
        "# ---------- Step 6: Time-based split 10:1:1 ----------\n",
        "total_len = len(labels_df)\n",
        "train_end = int(total_len * 10 / 12)\n",
        "val_end = int(total_len * 11 / 12)\n",
        "\n",
        "train_df = labels_df.iloc[:train_end].copy()\n",
        "val_df = labels_df.iloc[train_end:val_end].copy()\n",
        "test_df = labels_df.iloc[val_end:].copy()\n",
        "\n",
        "# ---------- Sanity check ----------\n",
        "assert train_df[\"submission_time\"].max() < val_df[\"submission_time\"].min(), \"Train must be before Val\"\n",
        "assert val_df[\"submission_time\"].max() < test_df[\"submission_time\"].min(), \"Val must be before Test\"\n",
        "\n",
        "print(\"‚úÖ Time-based split complete:\")\n",
        "print(f\"Train: {len(train_df)} samples\")\n",
        "print(f\"Val:   {len(val_df)} samples\")\n",
        "print(f\"Test:  {len(test_df)} samples\")\n",
        "\n",
        "# ---------- Step 7: Save CSVs only (no image move) ----------\n",
        "final_dataset_dir = \"/content/final_dataset\"\n",
        "os.makedirs(final_dataset_dir, exist_ok=True)\n",
        "\n",
        "train_df.to_csv(os.path.join(final_dataset_dir, \"train.csv\"), index=False)\n",
        "val_df.to_csv(os.path.join(final_dataset_dir, \"val.csv\"), index=False)\n",
        "test_df.to_csv(os.path.join(final_dataset_dir, \"test.csv\"), index=False)\n",
        "\n",
        "# ---------- Step 8: Zip everything ----------\n",
        "print(\"üì¶ Zipping final_dataset...\")\n",
        "shutil.make_archive(\"/content/final_dataset\", 'zip', final_dataset_dir)\n",
        "shutil.make_archive(\"/content/images_all\", 'zip', image_dir)\n",
        "\n",
        "# ---------- Step 9: Upload to Drive ----------\n",
        "# Copy all images into final_dataset/images/ before zipping\n",
        "print(\"üì• Copying all images into final_dataset/images/ ...\")\n",
        "dst_img_dir = os.path.join(final_dataset_dir, \"images\")\n",
        "os.makedirs(dst_img_dir, exist_ok=True)\n",
        "\n",
        "from glob import glob\n",
        "image_paths = glob(os.path.join(image_dir, \"*\"))\n",
        "for img_path in tqdm(image_paths, desc=\"Copying images\"):\n",
        "    shutil.copy(img_path, dst_img_dir)\n",
        "\n",
        "# Now zip entire final_dataset folder\n",
        "print(\"üì¶ Creating final_dataset.zip...\")\n",
        "final_zip_path = \"/content/final_dataset.zip\"\n",
        "with zipfile.ZipFile(final_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, _, files in os.walk(final_dataset_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, start=os.path.dirname(final_dataset_dir))\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "# Upload to Google Drive\n",
        "shutil.copy(final_zip_path, os.path.join(drive_input_dir, \"final_dataset.zip\"))\n",
        "print(f\"‚úÖ Uploaded final_dataset.zip with folder structure to Google Drive.\")\n"
      ],
      "metadata": {
        "id": "cBWK2aq4Lu85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b058f52-e5df-4e05-b474-7ccbefc7d597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Time-based split complete:\n",
            "Train: 11240 samples\n",
            "Val:   1124 samples\n",
            "Test:  1124 samples\n",
            "üì¶ Zipping final_dataset...\n",
            "üì• Copying all images into final_dataset/images/ ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10264/10264 [00:07<00:00, 1320.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Creating final_dataset.zip...\n",
            "‚úÖ Uploaded final_dataset.zip with folder structure to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "base_dir = \"/content/final_dataset\"\n",
        "image_dir = os.path.join(base_dir, \"images\")\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# Result summary\n",
        "total_missing = 0\n",
        "\n",
        "for split in splits:\n",
        "    csv_path = os.path.join(base_dir, f\"{split}.csv\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    missing_files = []\n",
        "    for fname in df[\"filename\"]:\n",
        "        if not os.path.exists(os.path.join(image_dir, fname)):\n",
        "            missing_files.append(fname)\n",
        "\n",
        "    num_missing = len(missing_files)\n",
        "    total = len(df)\n",
        "    valid = total - num_missing\n",
        "\n",
        "    print(f\"üìÇ {split}.csv: {total} records\")\n",
        "    print(f\"‚úÖ Found: {valid}\")\n",
        "    print(f\"‚ùå Missing: {num_missing}\")\n",
        "\n",
        "    if num_missing > 0:\n",
        "        print(\"‚ö†Ô∏è Example missing files (first 5):\", missing_files[:5])\n",
        "        # Optional: save list to file\n",
        "        with open(os.path.join(base_dir, f\"missing_in_{split}.txt\"), \"w\") as f:\n",
        "            for mf in missing_files:\n",
        "                f.write(f\"{mf}\\n\")\n",
        "\n",
        "    total_missing += num_missing\n",
        "\n",
        "print(\"\\n‚úÖ Done checking all CSV files.\")\n",
        "if total_missing == 0:\n",
        "    print(\"üéâ All images accounted for!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Total missing images: {total_missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUVIDSMiNRpw",
        "outputId": "41c914d0-4b11-4a4b-cf4f-7161a6968100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ train.csv: 11240 records\n",
            "‚úÖ Found: 11240\n",
            "‚ùå Missing: 0\n",
            "üìÇ val.csv: 1124 records\n",
            "‚úÖ Found: 1124\n",
            "‚ùå Missing: 0\n",
            "üìÇ test.csv: 1124 records\n",
            "‚úÖ Found: 1124\n",
            "‚ùå Missing: 0\n",
            "\n",
            "‚úÖ Done checking all CSV files.\n",
            "üéâ All images accounted for!\n"
          ]
        }
      ]
    }
  ]
}