#triton model config file
name: "qwen_vl_fine_tuned" # same name as the top level directoty 
platform: "python" #python backend
max_batch_size: 16 #would set according to gpu memory

# pretrained model expects an image as well as a prompt as imput
# the name, data type,  dimensions are 
input [
  {
    name: "INPUT_IMAGE"
    data_type: TYPE_UINT8
    dims: [ -1, -1, 3 ]  # Dynamic image dimensions
  },
  {
    name: "PROMPT"
    data_type: TYPE_STRING
    dims: [ -1 ]  # Dynamic text length
  }
]

output [
  {
    name: "prediction"
    data_type: TYPE_STRING
    dims: [ -1 ]
  },
  {
    name: "label"
    data_type: TYPE_STRING
    dims: [ -1 ]
  },
  {
    name: "reasoning"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]

instance_group [
  {
    count: 2  # Number of model instances
    kind: KIND_GPU
    gpus: [ 0, 1 ]  # Use both GPUs
  }
]

dynamic_batching {
  preferred_batch_size: [ 4, 8 ]
  max_queue_delay_microseconds: 100
}

optimization {
  execution_accelerators {
    gpu_execution_accelerator : [ {
      name : "tensorrt"
    }]
  }
} 