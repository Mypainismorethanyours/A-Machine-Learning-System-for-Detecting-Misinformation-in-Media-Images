{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McpkthmmeylZ",
        "outputId": "6f1a8c53-bce5-4ece-e046-0163dc526d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/65.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for undetected-chromedriver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 126516 files and directories currently installed.)\n",
            "Preparing to unpack chrome.deb ...\n",
            "Unpacking google-chrome-stable (135.0.7049.95-1) ...\n",
            "Setting up google-chrome-stable (135.0.7049.95-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q selenium undetected-chromedriver pandas tqdm\n",
        "!wget -q -O chrome.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get update -y > /dev/null\n",
        "!apt-get install -y libvulkan1 libnss3 libxss1 libgconf-2-4 libasound2 > /dev/null\n",
        "!dpkg -i chrome.deb\n",
        "!apt-get -f install -y > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!google-chrome --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmIbczwOiJq6",
        "outputId": "68050b38-e614-4f73-b2ce-ef640650f492"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Chrome 135.0.7049.95 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urlparse\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import shutil\n",
        "import uuid\n",
        "from google.colab import files\n",
        "\n",
        "import undetected_chromedriver as uc\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC"
      ],
      "metadata": {
        "id": "rZTLT4apez1M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload \"twigema_release.csv‚Äú (Expand Files at left side) ###"
      ],
      "metadata": {
        "id": "44DzdjxK1C-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CSV_PATH = \"/content/twigma_release.csv\"   # Upload the twigma_release.csv"
      ],
      "metadata": {
        "id": "y8w7WSX4e4mo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the Start and End for partial process ###"
      ],
      "metadata": {
        "id": "phjc44FP1arD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_base = \"/content/drive/MyDrive/twigma_batches\"\n",
        "os.makedirs(drive_base, exist_ok=True)\n",
        "\n",
        "# Launch headless Chrome browser\n",
        "options = uc.ChromeOptions()\n",
        "options.binary_location = \"/usr/bin/google-chrome\"\n",
        "options.add_argument(\"--headless=new\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "driver = uc.Chrome(options=options)\n",
        "\n",
        "# === BATCH MAIN FUNCTIONS ===\n",
        "def load_and_filter_data(current_start, current_end):\n",
        "    df_all = pd.read_csv(INPUT_CSV_PATH)\n",
        "    df_all[\"tweet_id\"] = df_all[\"id\"].astype(str)\n",
        "    df_chunk = df_all.iloc[current_start:current_end].copy()\n",
        "\n",
        "    tweet_counts = df_chunk[\"tweet_id\"].value_counts()\n",
        "    single_tweet_ids = tweet_counts[tweet_counts == 1].index\n",
        "    df_filtered = df_chunk[df_chunk[\"tweet_id\"].isin(single_tweet_ids)].copy()\n",
        "\n",
        "    print(f\"‚úÖ Processing {len(df_filtered)} single-image tweets only\")\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "\n",
        "def restart_driver():\n",
        "    global driver\n",
        "    try:\n",
        "        driver.quit()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    options = uc.ChromeOptions()\n",
        "    options.binary_location = \"/usr/bin/google-chrome\"\n",
        "    options.add_argument(\"--headless=new\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    driver = uc.Chrome(options=options)\n",
        "    print(\"‚ôªÔ∏è Driver restarted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzBBer1Px0js",
        "outputId": "c2723f3b-1442-44ac-c56a-b55b24a319c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Crawl ###"
      ],
      "metadata": {
        "id": "Xgdlm3Kb1n5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_batch(df, current_start, current_end):\n",
        "    global driver\n",
        "    OUTPUT_IMAGE_DIR = f\"/content/images_{current_start}_{current_end}\"\n",
        "    os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "    cdn_names = []\n",
        "    tweet_texts = []\n",
        "    image_success = []\n",
        "    text_success = []\n",
        "    row_indices = []\n",
        "\n",
        "    actual_requests = 0\n",
        "    sequent_requests = 0\n",
        "    consecutive_failures = 0\n",
        "    ALL_consecutive_failures = 0\n",
        "    recent_texts = []\n",
        "    recent_images = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing tweets\"):\n",
        "        tweet_id = row[\"tweet_id\"]\n",
        "        tweet_url = f\"https://twitter.com/i/web/status/{tweet_id}\"\n",
        "        row_index = row.name\n",
        "        media_url = \"\"\n",
        "        success = False\n",
        "        tweet_text = \"\"\n",
        "        text_ok = False\n",
        "\n",
        "        try:\n",
        "            driver.get(tweet_url)\n",
        "            actual_requests += 1\n",
        "            sequent_requests += 1\n",
        "\n",
        "            try:\n",
        "                tweet_elem = WebDriverWait(driver, 2.5).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//article//div[@data-testid=\"tweetText\"]'))\n",
        "                )\n",
        "                tweet_text = tweet_elem.text.strip()\n",
        "                text_ok = True\n",
        "            except:\n",
        "                print(f\"\\n[WARN] ‚ùå Failed to extract tweet text: {tweet_id}\")\n",
        "\n",
        "            try:\n",
        "                img_elem = WebDriverWait(driver, 0.5).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//article//img[contains(@src, \"pbs.twimg.com/media\")]'))\n",
        "                )\n",
        "                media_url = img_elem.get_attribute(\"src\")\n",
        "            except:\n",
        "                print(f\"\\n[WARN] ‚ùå Failed to locate image element: {tweet_id}\")\n",
        "\n",
        "            if media_url:\n",
        "                try:\n",
        "                    parsed = urlparse(media_url)\n",
        "                    cdn_filename = os.path.basename(parsed.path)\n",
        "                    if not re.search(r\"\\.(jpg|jpeg|png|webp)$\", cdn_filename):\n",
        "                        cdn_filename += \".jpg\"\n",
        "\n",
        "                    full_filename = f\"{tweet_id}_{cdn_filename}\"\n",
        "                    full_path = os.path.join(OUTPUT_IMAGE_DIR, full_filename)\n",
        "\n",
        "                    img_data = requests.get(media_url, timeout=5).content\n",
        "                    with open(full_path, \"wb\") as f:\n",
        "                        f.write(img_data)\n",
        "\n",
        "                    cdn_names.append(cdn_filename)\n",
        "                    success = True\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"[WARN] üåê Image download failed: {tweet_id} ‚Üí {media_url}\")\n",
        "                    cdn_names.append(media_url)\n",
        "            else:\n",
        "                cdn_names.append(\"\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] üö® Tweet {tweet_id} failed: {e}\")\n",
        "            cdn_names.append(\"\")\n",
        "            tweet_text = \"\"\n",
        "            text_ok = False\n",
        "\n",
        "        recent_texts.append(text_ok)\n",
        "        recent_images.append(success)\n",
        "\n",
        "        tweet_texts.append(tweet_text)\n",
        "        text_success.append(text_ok)\n",
        "        image_success.append(success)\n",
        "        row_indices.append(row_index)\n",
        "\n",
        "        if actual_requests % 10 == 0:\n",
        "            text_count = sum(recent_texts)\n",
        "            image_count = sum(recent_images)\n",
        "            both_count = sum(t and i for t, i in zip(recent_texts, recent_images))\n",
        "\n",
        "            print(f\"\\nüìä Summary of the last 10 requests:\")\n",
        "            print(f\"üìù Text success:  {text_count}/10\")\n",
        "            print(f\"üñºÔ∏è  Image success: {image_count}/10\")\n",
        "            print(f\"‚úÖ Both success:  {both_count}/10\\n\")\n",
        "            recent_texts = []\n",
        "            recent_images = []\n",
        "\n",
        "        if not text_ok and not success:\n",
        "            consecutive_failures += 1\n",
        "            ALL_consecutive_failures += 1\n",
        "        else:\n",
        "            consecutive_failures = 0\n",
        "            ALL_consecutive_failures = 0\n",
        "\n",
        "        if sequent_requests >= 10:\n",
        "            print(f\"‚ôªÔ∏è Restarting driver after {sequent_requests} requests...\")\n",
        "            restart_driver()\n",
        "            time.sleep(10)\n",
        "            consecutive_failures = 0\n",
        "            sequent_requests = 0\n",
        "\n",
        "        elif consecutive_failures >= 5:\n",
        "            print(f\"‚ôªÔ∏è Restarting driver after {consecutive_failures} consecutive failures...\")\n",
        "            restart_driver()\n",
        "            time.sleep(10)\n",
        "            consecutive_failures = 0\n",
        "            sequent_requests = 0\n",
        "            if ALL_consecutive_failures >= 10:\n",
        "                restart_driver()\n",
        "                time.sleep(20)\n",
        "                consecutive_failures = 0\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    return {\n",
        "        \"df\": df,\n",
        "        \"tweet_texts\": tweet_texts,\n",
        "        \"cdn_image_name\": cdn_names,\n",
        "        \"text_success\": text_success,\n",
        "        \"image_success\": image_success,\n",
        "        \"twigma_row\": row_indices,\n",
        "        \"duration\": duration,\n",
        "        \"output_image_dir\": OUTPUT_IMAGE_DIR\n",
        "    }"
      ],
      "metadata": {
        "id": "hUX5C63vrWxE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving CSV & Summary & File Download ###"
      ],
      "metadata": {
        "id": "UxRmGjvt1zGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(result_dict, current_start, current_end):\n",
        "    df = result_dict[\"df\"].copy()\n",
        "    df[\"tweet_text\"] = result_dict[\"tweet_texts\"]\n",
        "    df[\"cdn_image_name\"] = result_dict[\"cdn_image_name\"]\n",
        "    df[\"text_success\"] = result_dict[\"text_success\"]\n",
        "    df[\"image_success\"] = result_dict[\"image_success\"]\n",
        "    df[\"twigma_row\"] = result_dict[\"twigma_row\"]\n",
        "\n",
        "    output_csv = f\"twigma_scrape_rows_{current_start}_{current_end}.csv\"\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    total = len(df)\n",
        "    text_ok = df[\"text_success\"].sum()\n",
        "    image_ok = df[\"image_success\"].sum()\n",
        "    both_ok = ((df[\"text_success\"]) & (df[\"image_success\"])).sum()\n",
        "    duration = result_dict[\"duration\"]\n",
        "\n",
        "    def pct(x): return f\"{100 * x / total:.2f}%\"\n",
        "    def format_duration(seconds):\n",
        "        mins, secs = divmod(int(seconds), 60)\n",
        "        hrs, mins = divmod(mins, 60)\n",
        "        return f\"{hrs}h {mins}m {secs}s\"\n",
        "\n",
        "    summary_txt = output_csv.replace(\".csv\", \"_summary.txt\")\n",
        "    with open(summary_txt, \"w\") as f:\n",
        "        f.write(f\"{summary_txt}\\n\")\n",
        "        f.write(\"üìä Summary:\\n\")\n",
        "        f.write(f\"üìù Text: {text_ok}/{total} ({pct(text_ok)})\\n\")\n",
        "        f.write(f\"üñºÔ∏è  Image: {image_ok}/{total} ({pct(image_ok)})\\n\")\n",
        "        f.write(f\"‚úÖ Both: {both_ok}/{total} ({pct(both_ok)})\\n\")\n",
        "        f.write(f\"‚è±Ô∏è Duration: {format_duration(duration)} ({int(duration)}s)\\n\")\n",
        "        if both_ok > 0:\n",
        "            f.write(f\"‚è±Ô∏è Avg time per success: {duration / both_ok:.2f} seconds\\n\")\n",
        "\n",
        "    shutil.make_archive(result_dict[\"output_image_dir\"], 'zip', result_dict[\"output_image_dir\"])\n",
        "\n",
        "    # files.download(f\"{result_dict['output_image_dir']}.zip\")\n",
        "    # files.download(output_csv)\n",
        "    # files.download(summary_txt)\n",
        "    # print(\"üì¶ Downloads ready for:\", current_start, \"to\", current_end)\n",
        "\n",
        "    drive_base = \"/content/drive/MyDrive/twigma_batches\"\n",
        "    os.makedirs(drive_base, exist_ok=True)\n",
        "\n",
        "    shutil.copy(f\"{result_dict['output_image_dir']}.zip\", drive_base)\n",
        "    shutil.copy(output_csv, drive_base)\n",
        "    shutil.copy(summary_txt, drive_base)\n",
        "\n",
        "    print(f\"üìÇ Files saved to Google Drive folder: {drive_base}\")\n"
      ],
      "metadata": {
        "id": "0-HVNfLas0HH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main LOOP ###"
      ],
      "metadata": {
        "id": "0IWjSmzQ78pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_ROW = 30000\n",
        "END_ROW = 35000  # Set your own range\n",
        "BATCH_SIZE = 1000\n",
        "INPUT_CSV_PATH = \"twigma_release.csv\"\n",
        "\n",
        "# === MAIN EXECUTION LOOP ===\n",
        "for current_start in range(START_ROW, END_ROW, BATCH_SIZE):\n",
        "    current_end = min(current_start + BATCH_SIZE, END_ROW)\n",
        "    print(f\"\\nüöÄ Batch {current_start} to {current_end}\")\n",
        "    restart_driver()\n",
        "    df_filtered = load_and_filter_data(current_start, current_end)\n",
        "    result_dict = process_batch(df_filtered, current_start, current_end)\n",
        "    save_results(result_dict, current_start, current_end)"
      ],
      "metadata": {
        "id": "p7sC2Pt771Aw",
        "outputId": "dd2ea4f7-05ad-4c7b-9837-9a40869fe1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Batch 30000 to 30004\n",
            "‚ôªÔ∏è Driver restarted.\n",
            "‚úÖ Processing 4 single-image tweets only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1599871731006550016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:04<00:14,  4.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to locate image element: 1599871731006550016\n",
            "\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1599871237047533568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:09<00:09,  4.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to locate image element: 1599871237047533568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:13<00:04,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1599871105619009537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:17<00:00,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to locate image element: 1599871105619009537\n",
            "üìÇ Files saved to Google Drive folder: /content/drive/MyDrive/twigma_batches\n",
            "\n",
            "üöÄ Batch 30004 to 30008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ôªÔ∏è Driver restarted.\n",
            "‚úÖ Processing 0 single-image tweets only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Files saved to Google Drive folder: /content/drive/MyDrive/twigma_batches\n",
            "\n",
            "üöÄ Batch 30008 to 30010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-27-205d4b012e44>:18: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  def pct(x): return f\"{100 * x / total:.2f}%\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ôªÔ∏è Driver restarted.\n",
            "‚úÖ Processing 2 single-image tweets only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1599867359199911936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:08<00:08,  8.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to locate image element: 1599867359199911936\n",
            "\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1599867231252279297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[WARN] ‚ùå Failed to locate image element: 1599867231252279297\n",
            "üìÇ Files saved to Google Drive folder: /content/drive/MyDrive/twigma_batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retry (Not recommend for Efficiency) ###"
      ],
      "metadata": {
        "id": "WF4rhew7qUY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RE_START_ROW = 0\n",
        "# RE_END_ROW = 100  # Set your own range\n",
        "\n",
        "# # === CONFIG ===\n",
        "# RETRY_CSV_PATH = f\"twigma_scrape_rows_{RE_START_ROW}_{RE_END_ROW}.csv\"\n",
        "# OUTPUT_IMAGE_DIR = f\"images_{RE_START_ROW}_{RE_END_ROW}\"\n",
        "# os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "# options = uc.ChromeOptions()\n",
        "# options.binary_location = \"/usr/bin/google-chrome\"\n",
        "# options.add_argument(\"--headless=new\")\n",
        "# options.add_argument(\"--no-sandbox\")\n",
        "# options.add_argument(\"--disable-dev-shm-usage\")\n",
        "# driver = uc.Chrome(options=options)\n",
        "\n",
        "# # === LOAD DATA ===\n",
        "# df = pd.read_csv(RETRY_CSV_PATH)\n",
        "# df_retry = df[(df[\"text_success\"] == False) | (df[\"image_success\"] == False)].copy()\n",
        "# print(f\"üîÅ Total to retry: {len(df_retry)}\")\n",
        "\n",
        "# # === RECORD NEW RESULTS ===\n",
        "# new_text_success = 0\n",
        "# new_image_success = 0\n",
        "\n",
        "# for idx, row in tqdm(df_retry.iterrows(), total=len(df_retry), desc=\"üîÅ Retrying failed entries\"):\n",
        "#     tweet_id = str(row[\"tweet_id\"])\n",
        "#     tweet_url = f\"https://twitter.com/i/web/status/{tweet_id}\"\n",
        "#     cdn_image_old = row[\"cdn_image_name\"]\n",
        "\n",
        "#     # Retry flag\n",
        "#     got_text = False\n",
        "#     got_image = False\n",
        "\n",
        "#     try:\n",
        "#         driver.get(tweet_url)\n",
        "#         # time.sleep(0.5)\n",
        "\n",
        "#         # Retry text if it failed\n",
        "#         if row[\"text_success\"] == False:\n",
        "#             try:\n",
        "#                 tweet_elem = WebDriverWait(driver, 3).until(\n",
        "#                     EC.presence_of_element_located((By.XPATH, '//article//div[@data-testid=\"tweetText\"]'))\n",
        "#                 )\n",
        "#                 tweet_text = tweet_elem.text.strip()\n",
        "#                 df.loc[idx, \"tweet_text\"] = tweet_text\n",
        "#                 df.loc[idx, \"text_success\"] = True\n",
        "#                 new_text_success += 1\n",
        "#                 got_text = True\n",
        "#             except:\n",
        "#                 pass\n",
        "\n",
        "#         # Retry image if it failed\n",
        "#         if row[\"image_success\"] == False:\n",
        "#             try:\n",
        "#                 img_elem = WebDriverWait(driver, 1).until(\n",
        "#                     EC.presence_of_element_located((By.XPATH, '//article//img[contains(@src, \"pbs.twimg.com/media\")]'))\n",
        "#                 )\n",
        "#                 media_url = img_elem.get_attribute(\"src\")\n",
        "\n",
        "#                 parsed = urlparse(media_url)\n",
        "#                 cdn_filename = os.path.basename(parsed.path)\n",
        "#                 if not re.search(r\"\\.(jpg|jpeg|png|webp)$\", cdn_filename):\n",
        "#                     cdn_filename += \".jpg\"\n",
        "\n",
        "#                 full_filename = f\"{tweet_id}_{cdn_filename}\"\n",
        "#                 full_path = os.path.join(OUTPUT_IMAGE_DIR, full_filename)\n",
        "\n",
        "#                 img_data = requests.get(media_url, timeout=5).content\n",
        "#                 with open(full_path, \"wb\") as f:\n",
        "#                     f.write(img_data)\n",
        "\n",
        "#                 df.loc[idx, \"cdn_image_name\"] = cdn_filename\n",
        "#                 df.loc[idx, \"image_success\"] = True\n",
        "#                 new_image_success += 1\n",
        "#                 got_image = True\n",
        "\n",
        "#             except:\n",
        "#                 pass\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"[FAIL] Tweet {tweet_id}: {e}\")\n",
        "\n",
        "# driver.quit()\n",
        "\n",
        "# # === SAVE NEW MERGED RESULT ===\n",
        "# REPAIRED_CSV_PATH = RETRY_CSV_PATH.replace(\".csv\", \"_repaired.csv\")\n",
        "# df.to_csv(REPAIRED_CSV_PATH, index=False)\n",
        "\n",
        "# # === STATS ===\n",
        "# total_retry = len(df_retry)\n",
        "# final_total = len(df)\n",
        "# final_text = df[\"text_success\"].sum()\n",
        "# final_img = df[\"image_success\"].sum()\n",
        "# final_both = ((df[\"text_success\"]) & (df[\"image_success\"])).sum()\n",
        "\n",
        "# def pct(x, total): return f\"{100 * x / total:.2f}%\"\n",
        "\n",
        "# print(\"\\nüìä Retry Summary:\")\n",
        "# print(f\"üìù Newly recovered texts:  {new_text_success}/{total_retry} ({pct(new_text_success, total_retry)})\")\n",
        "# print(f\"üñºÔ∏è  Newly recovered images: {new_image_success}/{total_retry} ({pct(new_image_success, total_retry)})\")\n",
        "\n",
        "# print(\"\\nüì¶ Overall Total After Merge:\")\n",
        "# print(f\"üìù Total successful texts:  {final_text}/{final_total} ({pct(final_text, final_total)})\")\n",
        "# print(f\"üñºÔ∏è  Total successful images: {final_img}/{final_total} ({pct(final_img, final_total)})\")\n",
        "# print(f\"‚úÖ Fully successful entries: {final_both}/{final_total} ({pct(final_both, final_total)})\")\n",
        "\n",
        "# print(f\"\\n‚úÖ Updated CSV saved to: {REPAIRED_CSV_PATH}\")"
      ],
      "metadata": {
        "id": "5gvWZMQPqNxE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ‚úÖ Zip image directory\n",
        "# zip_name = OUTPUT_IMAGE_DIR + \".zip\"\n",
        "# shutil.make_archive(OUTPUT_IMAGE_DIR, 'zip', OUTPUT_IMAGE_DIR)\n",
        "\n",
        "# # ‚úÖ Download files\n",
        "# files.download(zip_name)\n",
        "# files.download(REPAIRED_CSV_PATH)\n",
        "\n",
        "# print(\"üì• Download links generated for Repaired-CSV and image archive.\")"
      ],
      "metadata": {
        "id": "xgGcC_w35lg5"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}