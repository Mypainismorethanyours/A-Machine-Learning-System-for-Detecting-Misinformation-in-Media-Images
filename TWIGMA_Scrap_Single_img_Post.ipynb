{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McpkthmmeylZ",
        "outputId": "45c110fe-0491-4d6a-c254-c499570a1528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "(Reading database ... 126633 files and directories currently installed.)\n",
            "Preparing to unpack chrome.deb ...\n",
            "Unpacking google-chrome-stable (135.0.7049.95-1) over (135.0.7049.95-1) ...\n",
            "Setting up google-chrome-stable (135.0.7049.95-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q selenium undetected-chromedriver pandas tqdm\n",
        "!wget -q -O chrome.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get update -y > /dev/null\n",
        "!apt-get install -y libvulkan1 libnss3 libxss1 libgconf-2-4 libasound2 > /dev/null\n",
        "!dpkg -i chrome.deb\n",
        "!apt-get -f install -y > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!google-chrome --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmIbczwOiJq6",
        "outputId": "16dc4a4a-147d-404d-c91b-c445e314f687"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Chrome 135.0.7049.95 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urlparse\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import shutil\n",
        "import uuid\n",
        "from google.colab import files\n",
        "\n",
        "import undetected_chromedriver as uc\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC"
      ],
      "metadata": {
        "id": "rZTLT4apez1M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload \"twigema_release.csv‚Äú (Expand Files at left side) ###"
      ],
      "metadata": {
        "id": "44DzdjxK1C-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CSV_PATH = \"/content/twigma_release.csv\"   # Upload the twigma_release.csv"
      ],
      "metadata": {
        "id": "y8w7WSX4e4mo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the Start and End for partial process ###"
      ],
      "metadata": {
        "id": "phjc44FP1arD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_ROW = 0\n",
        "END_ROW = 100  # Set your own range\n",
        "\n",
        "OUTPUT_IMAGE_DIR = f\"/content/images_{START_ROW}_{END_ROW}\"\n",
        "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "# Load and filter single-image tweets\n",
        "df_all = pd.read_csv(INPUT_CSV_PATH)\n",
        "df_all[\"tweet_id\"] = df_all[\"id\"].astype(str)\n",
        "df_chunk = df_all.iloc[START_ROW:END_ROW].copy()\n",
        "\n",
        "tweet_counts = df_chunk[\"tweet_id\"].value_counts()\n",
        "single_tweet_ids = tweet_counts[tweet_counts == 1].index\n",
        "df = df_chunk[df_chunk[\"tweet_id\"].isin(single_tweet_ids)].copy()\n",
        "print(f\"‚úÖ Processing {len(df)} single-image tweets only\")\n",
        "\n",
        "# Launch headless Chrome browser\n",
        "options = uc.ChromeOptions()\n",
        "options.binary_location = \"/usr/bin/google-chrome\"\n",
        "options.add_argument(\"--headless=new\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "driver = uc.Chrome(options=options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzBBer1Px0js",
        "outputId": "a525d8ac-a082-4714-8ce6-d5bfd259d8b3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Processing 61 single-image tweets only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Crawl ###"
      ],
      "metadata": {
        "id": "Xgdlm3Kb1n5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cdn_names = []\n",
        "tweet_texts = []\n",
        "image_success = []\n",
        "text_success = []\n",
        "row_indices = []\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing tweets\"):\n",
        "    tweet_id = row[\"tweet_id\"]\n",
        "    tweet_url = f\"https://twitter.com/i/web/status/{tweet_id}\"\n",
        "    row_index = row.name  # Original row number in the TWIGMA dataset\n",
        "\n",
        "    media_url = \"\"\n",
        "    success = False\n",
        "    tweet_text = \"\"\n",
        "    text_ok = False\n",
        "\n",
        "    try:\n",
        "        driver.get(tweet_url)\n",
        "        # time.sleep(0.5)\n",
        "\n",
        "        # ‚úÖ Extract tweet text\n",
        "        try:\n",
        "            tweet_elem = WebDriverWait(driver, 1.5).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//article//div[@data-testid=\"tweetText\"]'))\n",
        "            )\n",
        "            tweet_text = tweet_elem.text.strip()\n",
        "            text_ok = True\n",
        "        except:\n",
        "            print(f\"[WARN] ‚ùå Failed to extract tweet text: {tweet_id}\")\n",
        "\n",
        "        # ‚úÖ Extract image URL\n",
        "        try:\n",
        "            img_elem = WebDriverWait(driver, 0.5).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//article//img[contains(@src, \"pbs.twimg.com/media\")]'))\n",
        "            )\n",
        "            media_url = img_elem.get_attribute(\"src\")\n",
        "        except:\n",
        "            print(f\"[WARN] ‚ùå Failed to locate image element: {tweet_id}\")\n",
        "\n",
        "        # ‚úÖ Download image (record URL even if download fails)\n",
        "        if media_url:\n",
        "            try:\n",
        "                parsed = urlparse(media_url)\n",
        "                cdn_filename = os.path.basename(parsed.path)\n",
        "                if not re.search(r\"\\.(jpg|jpeg|png|webp)$\", cdn_filename):\n",
        "                    cdn_filename += \".jpg\"\n",
        "\n",
        "                full_filename = f\"{tweet_id}_{cdn_filename}\"\n",
        "                full_path = os.path.join(OUTPUT_IMAGE_DIR, full_filename)\n",
        "\n",
        "                img_data = requests.get(media_url, timeout=5).content\n",
        "                with open(full_path, \"wb\") as f:\n",
        "                    f.write(img_data)\n",
        "\n",
        "                cdn_names.append(cdn_filename)\n",
        "                success = True  # ‚Üê download successful\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] üåê Image download failed: {tweet_id} ‚Üí {media_url}\")\n",
        "                cdn_names.append(media_url)  # Save image URL for retry\n",
        "\n",
        "        else:\n",
        "            cdn_names.append(\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] üö® Tweet {tweet_id} failed: {e}\")\n",
        "        cdn_names.append(\"\")\n",
        "        tweet_text = \"\"\n",
        "        text_ok = False\n",
        "\n",
        "    # ‚úÖ Record result for each tweet\n",
        "    tweet_texts.append(tweet_text)\n",
        "    text_success.append(text_ok)\n",
        "    image_success.append(success)\n",
        "    row_indices.append(row_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUX5C63vrWxE",
        "outputId": "0150273f-c5ce-4939-eeb8-317945bdd570"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:   0%|          | 0/61 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608973782324252673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:   2%|‚ñè         | 1/61 [00:12<12:52, 12.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608973782324252673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets:   8%|‚ñä         | 5/61 [00:26<03:44,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608970676441960448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  10%|‚ñâ         | 6/61 [00:29<03:21,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608970676441960448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets:  16%|‚ñà‚ñã        | 10/61 [00:37<02:00,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608969867918544896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  18%|‚ñà‚ñä        | 11/61 [00:40<02:00,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608969867918544896\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608969819122171904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  20%|‚ñà‚ñâ        | 12/61 [00:42<01:59,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608969819122171904\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608969674544353281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  21%|‚ñà‚ñà‚ñè       | 13/61 [00:46<02:12,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608969353957085184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  23%|‚ñà‚ñà‚ñé       | 14/61 [00:49<02:16,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608969353957085184\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608969014767910913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  25%|‚ñà‚ñà‚ñç       | 15/61 [00:52<02:16,  2.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608969014767910913\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608968887411920898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  26%|‚ñà‚ñà‚ñå       | 16/61 [00:58<03:02,  4.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608968887411920898\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608968449048580097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  28%|‚ñà‚ñà‚ñä       | 17/61 [01:01<02:43,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608968449048580097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  30%|‚ñà‚ñà‚ñâ       | 18/61 [01:04<02:19,  3.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608967399885398016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  31%|‚ñà‚ñà‚ñà       | 19/61 [01:06<02:06,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608967399885398016\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608967188429537282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  33%|‚ñà‚ñà‚ñà‚ñé      | 20/61 [01:09<02:05,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608967188429537282\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608966914440675331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  34%|‚ñà‚ñà‚ñà‚ñç      | 21/61 [01:12<02:02,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608966914440675331\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608966285404037120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  36%|‚ñà‚ñà‚ñà‚ñå      | 22/61 [01:15<01:58,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608966285404037120\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608965933867106306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  38%|‚ñà‚ñà‚ñà‚ñä      | 23/61 [01:18<01:57,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608965933867106306\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608965361000648704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  39%|‚ñà‚ñà‚ñà‚ñâ      | 24/61 [01:22<01:55,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608965361000648704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 26/61 [01:26<01:30,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608961862196166659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 27/61 [01:28<01:27,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608961862196166659\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608961433047371778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 28/61 [01:31<01:24,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608961433047371778\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608961139307876352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 29/61 [01:34<01:27,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608961139307876352\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608961126275989509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 30/61 [01:37<01:25,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608961126275989509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 31/61 [01:40<01:24,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608957225669738501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 32/61 [01:43<01:23,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608957225669738501\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608957219361656832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 33/61 [01:45<01:16,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608957219361656832\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608954834962587649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 34/61 [01:48<01:11,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608954834962587649\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608954255104446464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 35/61 [01:50<01:08,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608954255104446464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 36/61 [01:53<01:07,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608951747564961794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 37/61 [01:57<01:15,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608951747564961794\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608950257005608965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 38/61 [02:00<01:12,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608950257005608965\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608949661783699457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 39/61 [02:03<01:08,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608949661783699457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 41/61 [02:09<00:55,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608946862069014529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 42/61 [02:11<00:51,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608946862069014529\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608946224622882816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 43/61 [02:14<00:47,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608946224622882816\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608946155378933762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 44/61 [02:16<00:44,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608946155378933762\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608946037150089217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 45/61 [02:19<00:42,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608946037150089217\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608945586199461889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 46/61 [02:22<00:41,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608945586199461889\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608944551808618496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 47/61 [02:25<00:39,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608944551808618496\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608944095363485696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 48/61 [02:28<00:36,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608944095363485696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 49/61 [02:30<00:31,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to extract tweet text: 1608943178283102211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 50/61 [02:33<00:31,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608943178283102211\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608942805308829697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 51/61 [02:36<00:27,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608942805308829697\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608942775957065728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 52/61 [02:38<00:23,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608942775957065728\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608942771725029378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 53/61 [02:41<00:22,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608942771725029378\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608942591311241219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 54/61 [02:44<00:20,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608942591311241219\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608941701065998337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 55/61 [02:47<00:17,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608941701065998337\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608941383695630336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 56/61 [02:50<00:14,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608941383695630336\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608941182511624194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 57/61 [02:53<00:11,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608941182511624194\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608939693957353473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 58/61 [02:55<00:08,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608939693957353473\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608939608330620930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 59/61 [02:58<00:05,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608939608330620930\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608939155337379840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing tweets:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 60/61 [03:01<00:02,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608939155337379840\n",
            "[WARN] ‚ùå Failed to extract tweet text: 1608938899845382145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 [03:04<00:00,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] ‚ùå Failed to locate image element: 1608938899845382145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving CSV ###"
      ],
      "metadata": {
        "id": "UxRmGjvt1zGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Save results to CSV\n",
        "df[\"tweet_text\"] = tweet_texts\n",
        "df[\"cdn_image_name\"] = cdn_names\n",
        "df[\"text_success\"] = text_success\n",
        "df[\"image_success\"] = image_success\n",
        "df[\"twigma_row\"] = row_indices\n",
        "\n",
        "OUTPUT_CSV_PATH = f\"twigma_scrape_rows_{START_ROW}_{END_ROW}.csv\"\n",
        "df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Results saved to: {OUTPUT_CSV_PATH}\")\n",
        "\n",
        "# === ‚úÖ Summary statistics ===\n",
        "total = len(df)\n",
        "text_ok = df[\"text_success\"].sum()\n",
        "image_ok = df[\"image_success\"].sum()\n",
        "both_ok = ((df[\"text_success\"]) & (df[\"image_success\"])).sum()\n",
        "\n",
        "def pct(x): return f\"{100 * x / total:.2f}%\"\n",
        "\n",
        "print(\"\\nüìä Summary:\")\n",
        "print(f\"üìù Tweets with text successfully extracted: {text_ok}/{total} ({pct(text_ok)})\")\n",
        "print(f\"üñºÔ∏è  Tweets with image successfully downloaded: {image_ok}/{total} ({pct(image_ok)})\")\n",
        "print(f\"‚úÖ Tweets with both text and image: {both_ok}/{total} ({pct(both_ok)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-HVNfLas0HH",
        "outputId": "152e60ac-2397-48d9-f3f2-529a0d52b4bf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Results saved to: twigma_scrape_rows_0_100.csv\n",
            "\n",
            "üìä Summary:\n",
            "üìù Tweets with text successfully extracted: 16/61 (26.23%)\n",
            "üñºÔ∏è  Tweets with image successfully downloaded: 17/61 (27.87%)\n",
            "‚úÖ Tweets with both text and image: 16/61 (26.23%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading Files ###"
      ],
      "metadata": {
        "id": "1dNEiuxe1-wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Zip image directory\n",
        "zip_name = OUTPUT_IMAGE_DIR + \".zip\"\n",
        "shutil.make_archive(OUTPUT_IMAGE_DIR, 'zip', OUTPUT_IMAGE_DIR)\n",
        "\n",
        "# ‚úÖ Download files\n",
        "files.download(zip_name)\n",
        "files.download(OUTPUT_CSV_PATH)\n",
        "\n",
        "print(\"üì• Download links generated for CSV and image archive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t638ok5e2Doh",
        "outputId": "e750f4fa-67f3-47b9-b841-3c70c9d7e0a6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_76311b0a-c8de-4dba-aba7-fb48ac0e2ed9\", \"images_0_100.zip\", 2947398)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4dd64d9c-b63a-4455-8c2a-d073b6d37dfe\", \"twigma_scrape_rows_0_100.csv\", 15958)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Download links generated for CSV and image archive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retry (Not recommend for Efficiency) ###"
      ],
      "metadata": {
        "id": "WF4rhew7qUY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RE_START_ROW = 0\n",
        "RE_END_ROW = 100  # Set your own range\n",
        "\n",
        "# === CONFIG ===\n",
        "RETRY_CSV_PATH = f\"twigma_scrape_rows_{RE_START_ROW}_{RE_END_ROW}.csv\"\n",
        "OUTPUT_IMAGE_DIR = f\"images_{RE_START_ROW}_{RE_END_ROW}\"\n",
        "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "options = uc.ChromeOptions()\n",
        "options.binary_location = \"/usr/bin/google-chrome\"\n",
        "options.add_argument(\"--headless=new\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "driver = uc.Chrome(options=options)\n",
        "\n",
        "# === LOAD DATA ===\n",
        "df = pd.read_csv(RETRY_CSV_PATH)\n",
        "df_retry = df[(df[\"text_success\"] == False) | (df[\"image_success\"] == False)].copy()\n",
        "print(f\"üîÅ Total to retry: {len(df_retry)}\")\n",
        "\n",
        "# === RECORD NEW RESULTS ===\n",
        "new_text_success = 0\n",
        "new_image_success = 0\n",
        "\n",
        "for idx, row in tqdm(df_retry.iterrows(), total=len(df_retry), desc=\"üîÅ Retrying failed entries\"):\n",
        "    tweet_id = str(row[\"tweet_id\"])\n",
        "    tweet_url = f\"https://twitter.com/i/web/status/{tweet_id}\"\n",
        "    cdn_image_old = row[\"cdn_image_name\"]\n",
        "\n",
        "    # Retry flag\n",
        "    got_text = False\n",
        "    got_image = False\n",
        "\n",
        "    try:\n",
        "        driver.get(tweet_url)\n",
        "        # time.sleep(0.5)\n",
        "\n",
        "        # Retry text if it failed\n",
        "        if row[\"text_success\"] == False:\n",
        "            try:\n",
        "                tweet_elem = WebDriverWait(driver, 3).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//article//div[@data-testid=\"tweetText\"]'))\n",
        "                )\n",
        "                tweet_text = tweet_elem.text.strip()\n",
        "                df.loc[idx, \"tweet_text\"] = tweet_text\n",
        "                df.loc[idx, \"text_success\"] = True\n",
        "                new_text_success += 1\n",
        "                got_text = True\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Retry image if it failed\n",
        "        if row[\"image_success\"] == False:\n",
        "            try:\n",
        "                img_elem = WebDriverWait(driver, 1).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//article//img[contains(@src, \"pbs.twimg.com/media\")]'))\n",
        "                )\n",
        "                media_url = img_elem.get_attribute(\"src\")\n",
        "\n",
        "                parsed = urlparse(media_url)\n",
        "                cdn_filename = os.path.basename(parsed.path)\n",
        "                if not re.search(r\"\\.(jpg|jpeg|png|webp)$\", cdn_filename):\n",
        "                    cdn_filename += \".jpg\"\n",
        "\n",
        "                full_filename = f\"{tweet_id}_{cdn_filename}\"\n",
        "                full_path = os.path.join(OUTPUT_IMAGE_DIR, full_filename)\n",
        "\n",
        "                img_data = requests.get(media_url, timeout=5).content\n",
        "                with open(full_path, \"wb\") as f:\n",
        "                    f.write(img_data)\n",
        "\n",
        "                df.loc[idx, \"cdn_image_name\"] = cdn_filename\n",
        "                df.loc[idx, \"image_success\"] = True\n",
        "                new_image_success += 1\n",
        "                got_image = True\n",
        "\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[FAIL] Tweet {tweet_id}: {e}\")\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# === SAVE NEW MERGED RESULT ===\n",
        "REPAIRED_CSV_PATH = RETRY_CSV_PATH.replace(\".csv\", \"_repaired.csv\")\n",
        "df.to_csv(REPAIRED_CSV_PATH, index=False)\n",
        "\n",
        "# === STATS ===\n",
        "total_retry = len(df_retry)\n",
        "final_total = len(df)\n",
        "final_text = df[\"text_success\"].sum()\n",
        "final_img = df[\"image_success\"].sum()\n",
        "final_both = ((df[\"text_success\"]) & (df[\"image_success\"])).sum()\n",
        "\n",
        "def pct(x, total): return f\"{100 * x / total:.2f}%\"\n",
        "\n",
        "print(\"\\nüìä Retry Summary:\")\n",
        "print(f\"üìù Newly recovered texts:  {new_text_success}/{total_retry} ({pct(new_text_success, total_retry)})\")\n",
        "print(f\"üñºÔ∏è  Newly recovered images: {new_image_success}/{total_retry} ({pct(new_image_success, total_retry)})\")\n",
        "\n",
        "print(\"\\nüì¶ Overall Total After Merge:\")\n",
        "print(f\"üìù Total successful texts:  {final_text}/{final_total} ({pct(final_text, final_total)})\")\n",
        "print(f\"üñºÔ∏è  Total successful images: {final_img}/{final_total} ({pct(final_img, final_total)})\")\n",
        "print(f\"‚úÖ Fully successful entries: {final_both}/{final_total} ({pct(final_both, final_total)})\")\n",
        "\n",
        "print(f\"\\n‚úÖ Updated CSV saved to: {REPAIRED_CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gvWZMQPqNxE",
        "outputId": "4ac6c420-66c2-450c-9dbc-29ed4ef20252"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Total to retry: 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÅ Retrying failed entries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [03:29<00:00,  4.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Retry Summary:\n",
            "üìù Newly recovered texts:  5/45 (11.11%)\n",
            "üñºÔ∏è  Newly recovered images: 5/45 (11.11%)\n",
            "\n",
            "üì¶ Overall Total After Merge:\n",
            "üìù Total successful texts:  21/61 (34.43%)\n",
            "üñºÔ∏è  Total successful images: 22/61 (36.07%)\n",
            "‚úÖ Fully successful entries: 21/61 (34.43%)\n",
            "\n",
            "‚úÖ Updated CSV saved to: twigma_scrape_rows_0_100_repaired.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Zip image directory\n",
        "zip_name = OUTPUT_IMAGE_DIR + \".zip\"\n",
        "shutil.make_archive(OUTPUT_IMAGE_DIR, 'zip', OUTPUT_IMAGE_DIR)\n",
        "\n",
        "# ‚úÖ Download files\n",
        "files.download(zip_name)\n",
        "files.download(REPAIRED_CSV_PATH)\n",
        "\n",
        "print(\"üì• Download links generated for Repaired-CSV and image archive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xgGcC_w35lg5",
        "outputId": "aceee72d-e6b2-4694-ede1-249da7faa4e2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f7e2c5da-8762-4675-a8ca-7fe4f348cb6f\", \"images_0_100.zip\", 3908582)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e5e7fdf9-af8d-447c-ad20-75c77df57a29\", \"twigma_scrape_rows_0_100_repaired.csv\", 16988)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Download links generated for Repaired-CSV and image archive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szDd36-Q6Vtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}