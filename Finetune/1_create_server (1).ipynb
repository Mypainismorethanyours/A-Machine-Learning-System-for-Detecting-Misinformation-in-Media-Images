{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, open this experiment on Trovi:\n",
    "\n",
    "-   Use this link: [Large-scale model training on Chameleon](https://chameleoncloud.org/experiment/share/39a536c6-6070-4ccf-9e91-bc47be9a94af) on Trovi\n",
    "-   Then, click “Launch on Chameleon”. This will start a new Jupyter server for you, with the experiment materials already in it.\n",
    "\n",
    "You will see several notebooks inside the `llm-chi` directory - look for the one titled `1_create_server.ipynb`. Open this notebook and continue there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring up a GPU server\n",
    "\n",
    "At the beginning of the lease time, we will bring up our GPU server. We will use the `python-chi` Python API to Chameleon to provision our server.\n",
    "\n",
    "We will execute the cells in this notebook inside the Chameleon Jupyter environment.\n",
    "\n",
    "Run the following cell, and make sure the correct project is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chi import server, context, lease\n",
    "import os\n",
    "\n",
    "context.version = \"1.0\" \n",
    "context.choose_project()\n",
    "context.choose_site(default=\"CHI@TACC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the string in the following cell to reflect the name of *your* lease (**with your own net ID**), then run it to get your lease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = lease.get_lease(f\"node-team5\") # or llm_single_netID, or llm_multi_netID\n",
    "l.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status should show as “ACTIVE” now that we are past the lease start time.\n",
    "\n",
    "The rest of this notebook can be executed without any interactions from you, so at this point, you can save time by clicking on this cell, then selecting Run \\> Run Selected Cell and All Below from the Jupyter menu.\n",
    "\n",
    "As the notebook executes, monitor its progress to make sure it does not get stuck on any execution error, and also to see what it is doing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the lease to bring up a server with the `CC-Ubuntu24.04-CUDA` disk image. (Note that the reservation information is passed when we create the instance!) This will take up to 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = os.getenv('USER') # all exp resources will have this prefix\n",
    "s = server.Server(\n",
    "    f\"node-team5\", \n",
    "    reservation_id=l.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
    ")\n",
    "s.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: security groups are not used at Chameleon bare metal sites, so we do not have to configure any security groups on this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we’ll associate a floating IP with the instance, so that we can access it over SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.associate_floating_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.check_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.show(type=\"widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docker with NVIDIA container toolkit\n",
    "\n",
    "To use common deep learning frameworks like Tensorflow or PyTorch, we can run containers that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")\n",
    "s.execute(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also install the NVIDIA container toolkit, with which we can access GPUs from inside our containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get NVIDIA container toolkit \n",
    "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
    "s.execute(\"sudo apt update\")\n",
    "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
    "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
    "s.execute(\"sudo systemctl restart docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we will verify that we can see our NVIDIA GPUs from inside a container, by passing `--gpus-all`. (The `-rm` flag says to clean up the container and remove its filesystem when it finishes running.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"docker run --rm --gpus all ubuntu nvidia-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull container for “Multiple GPU”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"sudo apt update; sudo apt -y install nvtop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"git clone --recurse-submodules https://github.com/Mypainismorethanyours/A-Machine-Learning-System-for-Detecting-Misinformation-in-Media-Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"docker build -t jupyter-mlflow -f A-Machine-Learning-System-for-Detecting-Misinformation-in-Media-Images/docker/Dockerfile.jupyter-torch-mlflow-cuda .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
